{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data (preparing and loading)\n",
    "\n",
    "Data can be almost anything... in machine learning\n",
    "\n",
    "* Excel spreadsheet\n",
    "* Images of any kind\n",
    "* Videos\n",
    "* Audio\n",
    "* DNA\n",
    "* Text, etc.\n",
    "\n",
    "Machine learning is a game of two parts:\n",
    "1. Get data into a numerical representation\n",
    "2. Build a model to learn patterns in that numerical representation\n",
    "\n",
    "To showcase this, let's create some *known* data using the linear regression formula. We'll use a linear regression formula to make a straight line with *known* **parameters**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "X[:10], y[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(X), len(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Splitting data into training and test sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_split = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize our data\n",
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions\n",
    "    :param train_data:\n",
    "    :param train_labels:\n",
    "    :param test_data:\n",
    "    :param test_labels:\n",
    "    :param predictions:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(train_data.cpu(), train_labels.cpu(), c=\"b\", s=4, label=\"Training data\")\n",
    "    plt.scatter(test_data.cpu(), test_labels.cpu(), c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data.cpu(), predictions.cpu(), c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "    plt.legend(prop={\"size\": 14})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_predictions()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Build model (linear regression)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1,\n",
    "                                                requires_grad=True,\n",
    "                                                dtype=torch.float))\n",
    "        self.bias = nn.Parameter(torch.randn(1,\n",
    "                                             requires_grad=True,\n",
    "                                             dtype=torch.float))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking the contents of our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "model_0.to(device)\n",
    "\n",
    "list(model_0.parameters())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making prediction using `torch.inference_mode()`\n",
    "\n",
    "To check our model's predictive power, let's see how well it predicts `y_test` based on `X_test`.\n",
    "\n",
    "When we pass data through our model, it will pass data through `forward()` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Train model\n",
    "\n",
    "The whole idea of training is for a model to move from some *unknown* parameters to some *known* ones. It can be done using loss function.\n",
    "\n",
    "**Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better.\n",
    "**Optimized:** Takes into account the loss of a model and adjusts the model's parameters to improve lose function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(),\n",
    "                            lr=0.01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building a training loop in PyTorch\n",
    "1. Look through data\n",
    "2. Forward pass (**forward propagation**)\n",
    "3. Calculate loss (compare predictions to ground truth)\n",
    "4. Optimizer zero grad\n",
    "5. Loss backward (calculate gradients for each parameter - **backpropagation**)\n",
    "6. Optimizer step (adjust parameters based on loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "epoch_count = []\n",
    "loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()  # set model to training mode\n",
    "\n",
    "    y_pred = model_0(X_train)  # forward pass\n",
    "    loss = loss_fn(y_pred, y_train)  # calculate the loss\n",
    "    optimizer.zero_grad()  # optimizer zero grad\n",
    "    loss.backward()  # backpropagation\n",
    "    optimizer.step()  # update parameters\n",
    "\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_0(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        loss_values.append(loss)\n",
    "        test_loss_values.append(test_loss)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    test_pred = model_0(X_test)\n",
    "    test_loss = loss_fn(test_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_predictions(predictions=test_pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(epoch_count, np.array(torch.tensor(loss_values).cpu().numpy()), label=\"Train Loss\")\n",
    "plt.plot(epoch_count, np.array(torch.tensor(test_loss_values).cpu().numpy()), label=\"Test Loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving a model in PyTorch\n",
    "1. `torch.save()` - allows to save a PyTorch object in Python's pickle format\n",
    "2. `torch.load()` - allows to load a saved PyTorch object\n",
    "3. `torch.nn.Module.load_state_dict()` - allows to load a model's saved state dictionary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"linear_regression_model_0.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "torch.save(obj=model_0.state_dict(),\n",
    "           f=MODEL_SAVE_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading a PyTorch model\n",
    "\n",
    "Since we saved our model's `state_dict()` rather than entire model, we'll create a new instance of our model class and load the saved `state_dict()` into that."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model_0 = LinearRegressionModel()\n",
    "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "loaded_model_0.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_0_preds = loaded_model_0(X_test)\n",
    "\n",
    "plot_predictions(predictions=loaded_model_0_preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
